{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word2Vec 模型**\n",
    "\n",
    "Word2Vec 是一种用于将单词表示为向量的技术，它是自然语言处理（NLP）中的一个关键方法。该模型的目标是将语言中的词汇映射到高维向量空间，以便单词之间的语义关系能够在向量空间中得以保留。Word2Vec 模型是通过训练神经网络来学习单词嵌入（word embeddings）的一种方法。\n",
    "\n",
    "以下是一个使用 `gensim` 库实现 Word2Vec 模型的简单示例代码：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector representation of 'word': [-0.00536227  0.00236431  0.0510335   0.09009273 -0.0930295  -0.07116809\n",
      "  0.06458873  0.08972988 -0.05015428 -0.03763372]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [Errno 11004]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# 示例文本\n",
    "corpus = \"Word embeddings are a type of word representation that allows words to be represented as vectors in a continuous vector space.\"\n",
    "\n",
    "# 分词\n",
    "tokenized_text = word_tokenize(corpus.lower())  # 转为小写以保持一致性\n",
    "\n",
    "# 定义 Word2Vec 模型\n",
    "model = Word2Vec(sentences=[tokenized_text], vector_size=10, window=5, sg=0, min_count=1)\n",
    "\n",
    "# 获取单词向量\n",
    "word_vector = model.wv['word']\n",
    "\n",
    "# 打印单词向量\n",
    "print(\"Vector representation of 'word':\", word_vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "在这个示例中：\n",
    "- `Word2Vec` 模型通过 `gensim` 库创建。\n",
    "- `vector_size` 参数定义了每个单词的向量维度。\n",
    "- `window` 参数定义了模型在训练时考虑的上下文窗口大小。\n",
    "- `sg` 参数表示使用 Skip-gram 模型（如果是 1）或 CBOW 模型（如果是 0）。\n",
    "- `min_count` 参数定义了在模型训练中忽略的最小词频。\n",
    "\n",
    "该模型通过训练神经网络，学习到了每个单词的向量表示。这些向量可以用于测量单词之间的相似性，执行词汇语义的数学运算，或作为更大 NLP 任务的输入。 Word2Vec 模型的训练需要大量文本数据，以便有效地捕捉词汇之间的复杂语义关系。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
