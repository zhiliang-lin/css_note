{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.723 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "张三\tnr\n",
      "在\tp\n",
      "上海\tns\n",
      "工作\tvn\n",
      "，\tx\n",
      "他\tr\n",
      "是\tv\n",
      "自然语言\tl\n",
      "处理\tv\n",
      "领域\tn\n",
      "的\tuj\n",
      "专家\tn\n",
      "。\tx\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "\n",
    "# 示例文本\n",
    "text = \"张三在上海工作，他是自然语言处理领域的专家。\"\n",
    "\n",
    "# 对文本进行分词和词性标注\n",
    "words = pseg.cut(text)\n",
    "\n",
    "# 输出分词和词性\n",
    "for word, pos in words:\n",
    "    print(f\"{word}\\t{pos}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "Could not find stanford-ner.jar jar file at /path/to/stanford-ner.jar",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32md:\\work\\github\\css_note\\css-nlp\\NER.ipynb Cell 2\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/work/github/css_note/css-nlp/NER.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m chinese_model_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/path/to/chinese.misc.distsim.crf.ser.gz\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/work/github/css_note/css-nlp/NER.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# 初始化Stanford NER标签器\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/work/github/css_note/css-nlp/NER.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m ner_tagger \u001b[39m=\u001b[39m StanfordNERTagger(chinese_model_path, stanford_ner_path, encoding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/work/github/css_note/css-nlp/NER.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# 示例文本\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/work/github/css_note/css-nlp/NER.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m张三在上海工作，他是自然语言处理领域的专家。\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32me:\\Program Files\\anaconda3\\lib\\site-packages\\nltk\\tag\\stanford.py:200\u001b[0m, in \u001b[0;36mStanfordNERTagger.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 200\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\Program Files\\anaconda3\\lib\\site-packages\\nltk\\tag\\stanford.py:70\u001b[0m, in \u001b[0;36mStanfordTagger.__init__\u001b[1;34m(self, model_filename, path_to_jar, encoding, verbose, java_options)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_JAR:\n\u001b[0;32m     65\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m     66\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe StanfordTagger class is not meant to be \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     67\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minstantiated directly. Did you mean \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     68\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mStanfordPOSTagger or StanfordNERTagger?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     69\u001b[0m     )\n\u001b[1;32m---> 70\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stanford_jar \u001b[39m=\u001b[39m find_jar(\n\u001b[0;32m     71\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_JAR, path_to_jar, searchpath\u001b[39m=\u001b[39;49m(), url\u001b[39m=\u001b[39;49m_stanford_url, verbose\u001b[39m=\u001b[39;49mverbose\n\u001b[0;32m     72\u001b[0m )\n\u001b[0;32m     74\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stanford_model \u001b[39m=\u001b[39m find_file(\n\u001b[0;32m     75\u001b[0m     model_filename, env_vars\u001b[39m=\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSTANFORD_MODELS\u001b[39m\u001b[39m\"\u001b[39m,), verbose\u001b[39m=\u001b[39mverbose\n\u001b[0;32m     76\u001b[0m )\n\u001b[0;32m     78\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_encoding \u001b[39m=\u001b[39m encoding\n",
      "File \u001b[1;32me:\\Program Files\\anaconda3\\lib\\site-packages\\nltk\\internals.py:848\u001b[0m, in \u001b[0;36mfind_jar\u001b[1;34m(name_pattern, path_to_jar, env_vars, searchpath, url, verbose, is_regex)\u001b[0m\n\u001b[0;32m    839\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_jar\u001b[39m(\n\u001b[0;32m    840\u001b[0m     name_pattern,\n\u001b[0;32m    841\u001b[0m     path_to_jar\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    846\u001b[0m     is_regex\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    847\u001b[0m ):\n\u001b[1;32m--> 848\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\n\u001b[0;32m    849\u001b[0m         find_jar_iter(\n\u001b[0;32m    850\u001b[0m             name_pattern, path_to_jar, env_vars, searchpath, url, verbose, is_regex\n\u001b[0;32m    851\u001b[0m         )\n\u001b[0;32m    852\u001b[0m     )\n",
      "File \u001b[1;32me:\\Program Files\\anaconda3\\lib\\site-packages\\nltk\\internals.py:734\u001b[0m, in \u001b[0;36mfind_jar_iter\u001b[1;34m(name_pattern, path_to_jar, env_vars, searchpath, url, verbose, is_regex)\u001b[0m\n\u001b[0;32m    732\u001b[0m         \u001b[39myield\u001b[39;00m path_to_jar\n\u001b[0;32m    733\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 734\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mLookupError\u001b[39;00m(\n\u001b[0;32m    735\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not find \u001b[39m\u001b[39m{\u001b[39;00mname_pattern\u001b[39m}\u001b[39;00m\u001b[39m jar file at \u001b[39m\u001b[39m{\u001b[39;00mpath_to_jar\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    736\u001b[0m         )\n\u001b[0;32m    738\u001b[0m \u001b[39m# Check environment variables\u001b[39;00m\n\u001b[0;32m    739\u001b[0m \u001b[39mfor\u001b[39;00m env_var \u001b[39min\u001b[39;00m env_vars:\n",
      "\u001b[1;31mLookupError\u001b[0m: Could not find stanford-ner.jar jar file at /path/to/stanford-ner.jar"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tag import StanfordNERTagger\n",
    "\n",
    "# 设置Stanford NER的路径和中文模型路径\n",
    "stanford_ner_path = '/path/to/stanford-ner.jar'\n",
    "chinese_model_path = '/path/to/chinese.misc.distsim.crf.ser.gz'\n",
    "\n",
    "# 初始化Stanford NER标签器\n",
    "ner_tagger = StanfordNERTagger(chinese_model_path, stanford_ner_path, encoding='utf-8')\n",
    "\n",
    "# 示例文本\n",
    "text = \"张三在上海工作，他是自然语言处理领域的专家。\"\n",
    "\n",
    "# 对文本进行实体识别\n",
    "entities = ner_tagger.tag(nltk.word_tokenize(text))\n",
    "\n",
    "# 输出识别的实体\n",
    "for entity in entities:\n",
    "    print(entity)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
